---
title: "R package `jmseq`: fitting joint models of longitudinal and time to event data by sequential Bayesian updating"
author: Paul McKeigue
output: rmarkdown::html_vignette
vignette: >
  \VignetteIndexEntry{xvalid}
  \VignetteEngine{knitr::rmarkdown}
  \VignetteEncoding{UTF-8}
---

```{r opts, include = FALSE, eval = TRUE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
  )

# devtools::check(vignettes=FALSE)
# devtools::document()
# devtools::build(vignettes=FALSE)
# R CMD INSTALL --library=~/R/x86_64-pc-linux-gnu-library/3.6 ./jmseq_0.0.0.9000.tar.gz

```

Joint modelling of longitudinal and time to event data can be efficiently implemented by sequential Bayesian updating.  

This vignette demonstrates an approximate two-step procedure, in which a linear Gaussian state space model is fitted to the longitudinal data, latent states at the start of each person-time interval are sampled from the forward updates generated by the Kalman filter, and these latent state values are plugged into a Poisson regression model for the event status at the end of each person-time interval.  


```{r setup, eval=TRUE}
library(data.table)
library(survival)
library(jmseq)
#source("../R/jmseqfunctions.R")
poissonglm.model <- rstan::stan_model(file="../stan/poissonglm.stan", verbose=TRUE)

opt_evalall <- TRUE # set this to TRUE to evaluate all code in the Rmarkdown source
opt_evalall <- FALSE # set this to TRUE to evaluate all code in the Rmarkdown source

## Options
options(rmarkdown.html_vignette.check_title = FALSE)
knitr::opts_chunk$set(echo = TRUE)
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
ggplot2::theme_set(ggplot2::theme_light(base_size = 8))

```

# Dataset
The Mayo Clinic primary biliary cirrhosis dataset comprises 1945 longitudinal observations of two biomarkers -- bilirubin and albumin -- on 312 individuals followed for mortality up to 15 years from baseline. There are two time-invariant covariates: sex and age at baseline, with treatment as an extra time-invariant covariate included in the survival dataset.  During follow-up there were 140 deaths.  Of these 48 deaths occurred during the 623.2 person-years of follow-up after the first 5 years.  

For joint modelling, we reformat the dataset as person-time intervals.  Person-time intervals longer than `max.interval` are split.  We set `max.interval` to 0 as a compromise between accuracy (short intervals) and computation time (long intervals).  The new intervals have missing values for the biomarker observations and event status set to 0. 

```{r pbc, eval=TRUE}
data(pbc, package="jmseq")
list2env(pbc, envir=environment())

nfolds <- 5
landmark.time <- 5
maxtime <- 15
set.seed <- 2345
max.interval <- 0.25

library(survival)

surv.split <- split.SurvLong(pbc$dataSurv, pbc$dataLong, max.interval=max.interval)
keep.long <- c("id", "Time", "tstop", timeinvar.long, biomarkers)
keep.surv <- c("id", timeinvar.surv, "Time", "tstop", "event") 
dataLong <- surv.split[, ..keep.long]
dataSurv <- surv.split[, ..keep.surv]

```

# Models for the longitudinal data
We shall compare two models for the biomarker data: a linear mixed model with random slopes, and a more general model with random slopes, autoregressive drift, and diffusion (Wiener process). 

```{r listmodels, eval=opt_evalall}
## create list of models
models.list <- listmodels(biomarkers, timeinvar.long)[c(1, 5)]

```

## Fitting the longitudinal model
Next we run `ctsem` to fit these models to the full dataset. 

```{r fitfullmodel, eval=opt_evalall}

lmmonly.fit <- ctstanfit.fold(train.dataset=dataLong, ctmodel=models.list[[1]])
lmmdriftdiff.fit <- ctstanfit.fold(train.dataset=dataLong, ctmodel=models.list[[2]])

```
## Comparison of longitudinal models
Comparing the fit of the model with drift, diffusion and random slopes to the linear mixed model shows that the model with drift and diffusion has higher log-likelihood and lower AIC.  


```{r compare, eval=TRUE}

s1 <- summary(lmmonly.fit)
s2 <- summary(lmmdriftdiff.fit)

compare <- rbind(data.frame(model="LMM only", loglik=s1$loglik, npars=s1$npars, aic=s1$aic),
                 data.frame(model="LMM + drift + diff", loglik=s2$loglik, npars=s2$npars, aic=s2$aic))

knitr::kable(data.table(model=names(models.list), compare))

```

# Generating forward updates of latent state values with the Kalman filter

## Example with five individuals

```{r plotfilter, eval=TRUE, fig.width=6}
## plot imputed values for first five individuals
ctsem::ctKalman(fit=lmmdriftdiff.fit, kalmanvec=c("y", "yprior"),
         subjects=1:5, plot=TRUE)
```

# Fitting the event model
## Imputing latent state values over all person-time intervals 
Next we generate imputed values of the latent state variables from the forward updates of the state probabilities computed by the Kalman filter.  In each training fold, the forward updates continue to the end of the follow-up period including the person-time intervals in the test fold, where the biomarker observations have been dropped.  

```{r impute, eval=opt_evalall}
latent.updates <- kalmanwide(lmmdriftdiff.fit, subjects="all",
                             timestep="asdata",
                             timerange=c(0, maxtime))
```

## Using the imputed latent state values in a Poisson regression model for event status 
These  latent state values at the start of the interval are plugged into a Poisson regression model for the event status at the end of each interval. 

We have three options for fitting the Poisson regression model: the R function 'glm', ('stan=FALSE') a variational Bayes algorithm with Stan ('stan=TRUE, vb=TRUE'), or using Stan to find the posterior mode ('stan=TRUE, vb=FALSE').  The Stan options are included as a first step in development of a one-step joint model.   


```{r poisson, eval=opt_evalall}

## fit Poisson model to training datasets for each fold within each ctsem model
poisson.glm.beta <- fit.poissontsplit(latent.updates,
                                      dataSurv, 
                                      timeinvar.surv, biomarkers, splines=FALSE,
                                      stan=TRUE, vb=TRUE)

if(colnames(poisson.glm.beta)[1]=="Estimate") {
    coeffs <- poisson.glm.beta
}
```

A table of the regression coefficients for the Poisson model is shown below. 

```{r printcoeffs, eval=TRUE}
knitr::kable(coeffs,
      digits=c(2, 2, 2, 4),
      caption="Poisson time-splitting model fitted to latent biomarker values imputed by Kalman filter from linear mixed model with diffusion and drift")

```

# Cross-validation
## Test-training split
For cross-validation of the prediction of events, we split the dataset into test and training folds.  Each test fold contains all observations after the landmark time on the individuals in that test fold.  Each training fold contains all observations up to the landmark time and observations after the landmark time in those individuals who are not in the corresponding test fold. For those individuals who are in the corresponding test fold, the biomarker observations after the landmark time are set to missing. 

```{r split, eval=opt_evalall}

ids.tosample <- unique(dataSurv[Time > landmark.time, id]) # & dataSurv$Time < max(dataSurv$Time))
ids.permuted <- base::sample(ids.tosample)
## test-train split for nfold cross-validation
folds <- cut(1:length(ids.permuted), breaks=nfolds, labels=FALSE)

## create list of ids in each testfolds 
ids.test <- vector("list", nfolds)
for(i in 1:nfolds) {
    ids.test[[i]] <- ids.permuted[folds==i]
}

## create training datasets
train.datasets <- vector("list", nfolds)
for(i in 1:nfolds) {
    train.datasets[[i]] <- vector("list", 3)
    names(train.datasets[[i]]) <- c("Surv", "Long", "ids.test")
    train.datasets[[i]]$Surv <- trainsplit.surv(ids.test=ids.test[[i]],
                                                dataSurv=dataSurv,
                                                landmark.time=landmark.time) 
    train.datasets[[i]]$Long <- trainsplit.long(ids.test[[i]],
                                                dataLong=dataLong, landmark.time,
                                                biomarkers)
    train.datasets[[i]]$ids.test <- ids.test[[i]]
}
```


## Fitting the longitudinal models to training folds
Next we run `ctsem` to fit each of these models to each training fold. The fitted models are saved in `fitted.list`.  This step is parallelised over folds using `parLapply`. 

```{r train, eval=opt_evalall}
## mclapply and foreach %dopar% fail -- child processes cannot open sockets
start <- Sys.time()
cl <- parallel::makePSOCKcluster(8)
fitted.list <- vector("list", length(models.list))
names(fitted.list) <- names(models.list)
cat("Looping over ctsem models to fit to training datasets ...\n")
for(m in 1:length(models.list)) {
    fitted.list[[m]] <- 
     #lapply(X=train.datasets, FUN=ctstanfit.fold, ctmodel=models.list[[m]]) 
     parallel::parLapply(cl, X=train.datasets, fun=ctstanfit.fold, ctmodel=models.list[[m]]) 
     gc()
    names(fitted.list[[m]]) <- paste0("fold", 1:nfolds)
}
parallel::stopCluster(cl)
cat("done, time ", difftime(Sys.time(), start, "mins"), "minutes\n")

```

## Imputing latent state values over all person-time intervals 
Next we generate imputed values of the latent state variables from the forward updates of the state probabilities computed by the Kalman filter.  In each training fold, the forward updates continue to the end of the follow-up period including the person-time intervals in the test fold, where any biomarker observations have been set to missing.  This step is parallelised over folds using `mcmapply`. 

```{r imputecv, eval=opt_evalall}
## generate imputations from each training fold within each ctsem model
## we have to run the imputations up to maxtime for everyone, then censor later
start <- Sys.time()
cat("Looping over ctsem models to generate imputations from Kalman filter ...\n")
kalwide.list <- vector("list", length(models.list))
names(kalwide.list) <- names(models.list)
for(m in 1:length(models.list)) {
    kalwide.list[[m]] <- parallel::mcmapply(FUN=kalmanwide,
                                fitted.list[[m]],
                                MoreArgs=list(timestep="asdata",
                                              timerange=c(0, maxtime)),
                                SIMPLIFY=FALSE)
}
cat("done, time ",  difftime(Sys.time(), start, "mins"), "minutes\n")

imputed.test <- kalwide.list[[2]][[1]][Subject %in% ids.test[[1]]]
imputed.first5ids <- unique(imputed.test$id)[1:5]
imputed.test <- imputed.test[id %in% imputed.first5ids]
imputed.test[, id := factor(id)]
library(ggplot2)
ggplot(data=imputed.test, aes(x=tstart, y=logBili, color=id)) + geom_line()

## no need to censor imputations at censoring time for each individual. 
## test dataset: retain rows with ids in test fold and imputed values after landmark.time.
## train dataset: drop rows after landmark time for those in test fold
kalwide.test.list <- vector("list", length(models.list))
kalwide.train.list <- vector("list", length(models.list))
for(m in 1:length(models.list)) {
    kalwide.test.list[[m]] <- mapply(FUN=function(k, ids.keep) 
        k[id %in% ids.keep & tstart > landmark.time], 
        kalwide.list[[m]],
        ids.test,
        SIMPLIFY=FALSE)

    kalwide.train.list[[m]] <- mapply(FUN=function(k, ids.drop)
        k[!(id %in% ids.drop & tstart > landmark.time)],
        kalwide.list[[m]],
        ids.test, 
        SIMPLIFY=FALSE)
}

```

## Training a Poisson regression model for event status on imputed latent states 
The  latent state values at the start of the interval are plugged into a Poisson regression model for the event status at the end of each interval. 


```{r poissoncv, eval=opt_evalall}
## fit Poisson model to training datasets for each fold within each ctsem model
coeffs.train <- vector("list", length(models.list))
for(m in 1:length(models.list)) {
    coeffs.train[m] <- vector("list", length(nfolds))
    for(fold in 1:nfolds) {
        coeffs.train[[m]][[fold]] <- fit.poissontsplit(kalwide.train.list[[m]][[fold]],
                                                   train.datasets[[fold]]$Surv,
                                                   timeinvar.surv, biomarkers, splines=FALSE,
                                                   stan=FALSE)
    }
}
names(coeffs.train) <- names(models.list)

```

## Prediction of event status on test folds
The final step is to use the Poisson regression model fitted to each training fold to generate predictions of event status on the test folds from the forward predictions of the latent states.  Predictive performance is evaluated by concatenating observed and predicted event status over all test folds.  

```{r predict, eval=opt_evalall}
## generate predictions on test folds 
## elements of testdata.list are concatenations of all test folds 
testdata.list <- vector("list", length(models.list))
names(testdata.list) <- names(models.list)
for(m in 1:length(models.list)) {
    ## vectorize over folds: args before MoreArgs are lists of folds
    testdata.model.list <- mapply(FUN=predict.testdata,
                                  beta=coeffs.train[[m]],
                                  imputed.dt=kalwide.test.list[[m]],
                                  MoreArgs=list(dataSurv=dataSurv,
                                                timeinvar.surv=timeinvar.surv,
                                                biomarkers=biomarkers,
                                                landmark.time=landmark.time),
                                  SIMPLIFY=FALSE)
    testdata.list[[m]] <- data.table::rbindlist(testdata.model.list)
}

## generate summary table of predictive performance
predict.table <- NULL
for(i in 1:length(testdata.list)) {
    stats <- tabulate.predictions(testdata.list[[i]])
    predict.table <- rbind(predict.table, stats)
}
predict.table <- data.table(Model=names(testdata.list), predict.table)
predict.table[, Predicted := as.numeric(Predicted)]
predict.table[, `Person-years` := as.numeric(`Person-years`)]
predict.table [, `Log score` := as.numeric(`Log score`)]
predict.table[, `C-statistic` := as.numeric(`C-statistic`)]

```

The cross-validated predictive performance of the event submodels is summarised in a table. For the C-statistic to be valid, we have to set the length of the last time interval in each individual to the maximum value.  The total person-years of follow-up is thus longer than the true value.  This discrepancy can be made arbitrarily small by splitting the follow-up time into short person-time intervals, but this increases the computation time.  

```{r tablemodels, eval=TRUE}
knitr::kable(predict.table)
```

The model with drift and diffusion has better predictive performance (higher test log-likelihood) though the difference in C-statistic is small. 
